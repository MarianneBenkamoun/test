{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Based Machine Learning Algorithm\n",
    "\n",
    "[An introduction to machine learning with scikit-learn](http://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scikit-learn Definition:\n",
    "\n",
    "**Supervised learning**, in which the data comes with additional attributes that we want to predict. This problem can be either:\n",
    "\n",
    "* **Classification**: samples belong to two or more *classes* and we want to learn from already labeled data how to predict the class of unlabeled data. An example of classification problem would be the handwritten digit recognition example, in which the aim is to assign each input vector to one of a finite number of discrete categories. Another way to think of classification is as a discrete (as opposed to continuous) form of supervised learning where one has a limited number of categories and for each of the n samples provided, one is to try to label them with the correct category or class.\n",
    "\n",
    "\n",
    "* **Regression**: if the desired output consists of one or more *continuous variables*, then the task is called regression. An example of a regression problem would be the prediction of the length of a salmon as a function of its age and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST dataset - a set of 70,000 small images of digits handwritten. You can read more via [The MNIST Database](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A function that can read MNIST's idx file format into numpy arrays.\n",
    "    The MNIST data files can be downloaded from here:\n",
    "    \n",
    "    http://yann.lecun.com/exdb/mnist/\n",
    "    This relies on the fact that the MNIST dataset consistently uses\n",
    "    unsigned char types with their data segments.\n",
    "\"\"\"\n",
    "import gzip\n",
    "\n",
    "import struct\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename) as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "X_train = read_idx('X_train.gz')\n",
    "y_train = read_idx('y_train.gz')\n",
    "X_test = read_idx('X_test.gz')\n",
    "y_test = read_idx('y_test.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  38,  48,  48,  22,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         62,  97, 198, 243, 254, 254, 212,  27,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  67,\n",
       "        172, 254, 254, 225, 218, 218, 237, 248,  40,   0,  21, 164, 187,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  89, 219,\n",
       "        254,  97,  67,  14,   0,   0,  92, 231, 122,  23, 203, 236,  59,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 217, 242,\n",
       "         92,   4,   0,   0,   0,   0,   4, 147, 253, 240, 232,  92,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 101, 255,  92,\n",
       "          0,   0,   0,   0,   0,   0, 105, 254, 254, 177,  11,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 167, 244,  41,\n",
       "          0,   0,   0,   7,  76, 199, 238, 239,  94,  10,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 192, 121,   0,\n",
       "          0,   2,  63, 180, 254, 233, 126,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 190, 196,  14,\n",
       "          2,  97, 254, 252, 146,  52,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 130, 225,  71,\n",
       "        180, 232, 181,  60,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 130, 254, 254,\n",
       "        230,  46,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   6,  77, 244, 254, 162,\n",
       "          4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 110, 254, 218, 254, 116,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 131, 254, 154,  28, 213,  86,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  66, 209, 153,  19,  19, 233,  60,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 142, 254, 165,   0,  14, 216, 167,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  90, 254, 175,   0,  18, 229,  92,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  26, 229, 249, 176, 222, 244,  44,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  73, 193, 197, 134,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[59999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[59999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13fba668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = X_train[1000]\n",
    "#_image = _.reshape(28, 28)\n",
    "plt.imshow(_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_train == 4)\n",
    "y_train[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Locating the number 4 and plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59716</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59722</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59727</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59743</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59753</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59759</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59766</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59772</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59780</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59789</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59799</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59809</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59821</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59852</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59862</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59863</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59874</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59879</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59881</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59893</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59900</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59905</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59915</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59922</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59931</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59933</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59951</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59975</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col\n",
       "2        4\n",
       "9        4\n",
       "20       4\n",
       "26       4\n",
       "53       4\n",
       "58       4\n",
       "60       4\n",
       "61       4\n",
       "64       4\n",
       "89       4\n",
       "92       4\n",
       "115      4\n",
       "127      4\n",
       "131      4\n",
       "139      4\n",
       "142      4\n",
       "150      4\n",
       "163      4\n",
       "164      4\n",
       "166      4\n",
       "194      4\n",
       "217      4\n",
       "222      4\n",
       "237      4\n",
       "257      4\n",
       "271      4\n",
       "272      4\n",
       "275      4\n",
       "289      4\n",
       "292      4\n",
       "...    ...\n",
       "59716    4\n",
       "59722    4\n",
       "59727    4\n",
       "59743    4\n",
       "59753    4\n",
       "59759    4\n",
       "59766    4\n",
       "59772    4\n",
       "59780    4\n",
       "59789    4\n",
       "59799    4\n",
       "59809    4\n",
       "59821    4\n",
       "59852    4\n",
       "59862    4\n",
       "59863    4\n",
       "59874    4\n",
       "59879    4\n",
       "59881    4\n",
       "59893    4\n",
       "59900    4\n",
       "59905    4\n",
       "59915    4\n",
       "59922    4\n",
       "59931    4\n",
       "59933    4\n",
       "59941    4\n",
       "59943    4\n",
       "59951    4\n",
       "59975    4\n",
       "\n",
       "[5842 rows x 1 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(y_train)\n",
    "np.where(y_train==4)\n",
    "df.columns = ['col']\n",
    "df.loc[df['col']==4,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1046f470>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103e8518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1044c2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = X_train[24754]\n",
    "_image = _.reshape(28, 28)\n",
    "plt.imshow(_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59000, 28, 28)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1000].shape\n",
    "X_train[1000:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24600, 52491, 52186, ..., 35926, 18664, 30384])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "indices = np.arange(X_train.shape[0])\n",
    "random.shuffle(indices)\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_split = 60000\n",
    "\n",
    "#X_train, X_test, y_train, y_test = X[:num_split], X[num_split:], y[:num_split], y[num_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips**: Typically we shuffle the training set. This ensures the training set is randomised and your data distribution is consistent. However, shuffling is a bad idea for time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Alternative Method](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle_index = np.random.permutation(num_split)\n",
    "X_train, y_train = X_train[indices], y_train[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_0 = y_train.copy()\n",
    "y_train_0[np.where(y_train_0!=0)] = 1\n",
    "    \n",
    "    \n",
    "y_test_0 = y_test.copy()\n",
    "y_test_0[np.where(y_test_0!=0)]=1\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify our problem, we will make this an exercise of \"zero\" or \"non-zero\", making it a two-class problem.\n",
    "\n",
    "We need to first convert our target to 0 or non zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_0 = (y_train == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_0 = (y_test == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can pick any classifier and train it. This is the iterative part of choosing and testing all the classifiers and tuning the hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier\n",
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=0, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "X_train = X_train.reshape(60000,-1)\n",
    "X_test = X_test.reshape(10000,-1)\n",
    "clf = SGDClassifier(random_state = 0)\n",
    "clf.fit(X_train, y_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  13, 105, 105, 219, 253, 255, 253, 253, 253,\n",
       "        91,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   4, 130, 208, 213, 252, 252, 252, 252, 253, 252,\n",
       "       252, 252, 239,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  39, 169, 252, 252, 252, 252, 237, 237, 237,\n",
       "       238, 237, 246, 252, 252, 222,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  60, 252, 252, 252, 167, 132,   8,\n",
       "         0,   0,   0,   0, 164, 252, 252, 151,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  42, 181, 252, 252, 118,\n",
       "         0,   0,   0,   0,  76, 198, 242, 252, 229,  52,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,  74,\n",
       "       127, 225,  30,  30,  57, 178, 253, 252, 252, 237,  69,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  64, 169, 252, 252, 252, 252, 252, 253, 252, 244,  63,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 120, 252, 252, 252, 252, 252, 252, 253, 252, 251,\n",
       "       238, 107,  26,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  28, 190, 212, 252, 252, 244, 233, 253,\n",
       "       252, 252, 252, 252, 193,  45,   3,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  13, 103, 103,  85,\n",
       "        61, 104, 138, 252, 252, 252, 252, 252, 102,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 163, 253, 253, 253, 227,  43,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  13,  61, 224, 252,\n",
       "       252, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        47, 243, 252, 199,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   8, 120, 120, 120, 120,   7,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 238, 252, 252,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  31, 198, 225, 252, 252, 252, 252,  14,   0,   0,   0,   0,\n",
       "         0,   0,   0,  27, 223, 250, 252, 120,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 210, 252, 252, 252, 243, 117,  74,   4,   0,   0,\n",
       "         0,  25,  30,  30, 162, 187, 252, 252, 246,  91,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 174, 252, 252, 252, 217, 134, 134, 134,\n",
       "       134, 134, 134, 231, 252, 252, 252, 252, 252, 252, 128,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   6, 158, 252, 252, 252, 252,\n",
       "       252, 252, 252, 252, 253, 252, 252, 252, 252, 241, 162, 110,   4,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14,  67, 207,\n",
       "       207, 239, 252, 252, 252, 252, 253, 252, 222, 207, 207,  95,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  74, 103, 103, 103, 103, 104, 103,  36,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SGDClassifier instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-220-b307407ceb03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coef_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[1;32m--> 255\u001b[1;33m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This SGDClassifier instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_train[1000].reshape(1, -1))\n",
    "pd.DataFrame([y_train_0[1000]],[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8585908864654509\n",
      "0.9875\n",
      "the model score is 0.9875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(r2_score(y_test_0,pred_test))\n",
    "print(clf.score(X_test,y_test_0))\n",
    "\n",
    "pouet = pred_test== y_test_0\n",
    "correct = np.where(pouet == True)\n",
    "percentage = np.array(correct).flatten().shape[0]/10000\n",
    "print(f'the model score is {percentage}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measures\n",
    "\n",
    "# Measuring Accuracy Using Cross-Validation\n",
    "\n",
    "## StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the `StratifiedKFold` stratified sampling to create multiple folds. At each iteration, the classifier was cloned and trained using the training folds and makes predictions on the test fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "clf = SGDClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "    skfolds = StratifiedKFold(n_splits=3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19959 19961 19975 ... 59997 59998 59999]\n",
      "[    0     1     2 ... 20005 20006 20007]\n",
      "---\n",
      "[    0     1     2 ... 59997 59998 59999]\n",
      "[19959 19961 19975 ... 40362 40381 40382]\n",
      "---\n",
      "[    0     1     2 ... 40362 40381 40382]\n",
      "[39969 39970 39971 ... 59997 59998 59999]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skfolds.split(X_train, y_train_0):\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9873\n",
      "0.9873006349682516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9873\n",
      "0.98735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900\n",
      "0.9900495024751238\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skfolds.split(X_train, y_train_0):\n",
    "    clone_clf = clone(clf)\n",
    "    X_train_fold = X_train[train_index]\n",
    "    y_train_folds = (y_train_0[train_index])\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = (y_train_0[test_index])\n",
    "    \n",
    "    clone_clf.fit(X_train_fold, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(\"{0:.4f}\".format(n_correct / len(y_pred)))\n",
    "    print(f\"{clone_clf.score(X_test_fold,y_test_fold)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cross_val_score` using K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross-validation splits the training set into K-folds and then make predictions and evaluate them on each fold using a model trained on the remaning folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98730063, 0.98735   , 0.9900495 ])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_train, y_train_0, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Danger of Blindly Applying Evaluator As a Performance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check against a dumb classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.6906375997653456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marianne\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHCNJREFUeJzt3XlwndWd5vHvuZt26VqSjYU3ybIsW2AbsMHg6Rl2TNImEEJcnarOJCk3DMxMp3qmCMU0lZqp6a7pzkwghBqqiKdCGtKdhEwIhAQMTMwSEhaveMHIWJJlYSMvkixru5LucuYP6TqO13ule99Ffj5VrpJ83/ue36krP351znnPa6y1iIiI+wJuFyAiImMUyCIiHqFAFhHxCAWyiIhHKJBFRDxCgSwi4hEKZBERj1Agi4h4hAJZRMQjQtkcXF1dbWtra/NUiojI1LR169Yua+30Cx2XVSDX1tayZcuWiVclInIRMsYcyOQ4DVmIiHiEAllExCMUyCIiHqFAFhHxCAWyiIhHKJBFRDxCgSwi4hEKZBERj1Agi4h4hAJZRMQjFMgiIh6hQBYR8QgFsoiIRyiQRUQ8QoEsIuIRCmQREY9QIIuIeIQCWUTEIxTIIiIeoUAWkSkrFou5XUJWFMgiMiW99NJLrLnjDjZu3Oh2KRlTIIvIlJNKpfjJT39KIpHg7/7+73nxxRfdLikjCmQRmXI++OADDnd2Mlz3r0lUzOHxxx/n2WefdbusC1Igi8iU8/wvf4mJFJOorCe24CbiVfU8/fTT7Nu3z+3SzkuBLCJTSkdHB1s2b2a4uhECATABRmZfDcDWrVtdru78FMgiMqW88MILEAgQn7Ho5N/ZSDEURdm2bbuLlV2YAllEpozBwUFe2bCB+LQ6bLjoT14bLZvJjh07SCQSLlV3YQpkEZkyNm7cyMjwMKMzms54LVl2KSMjwzQ3N7tQWWYUyCIyZezYsQNTUEqqdPoZryXKZwKwbds2p8vKmAJZRKaMj/Z8zGhR1dlfDBViS6oUyCIi+dbf38/hzs9IlVSf85h46Ux27/6IkZERByvLnAJZRKaEvXv3ApA8TyAnymtIJOLs2bPHqbKyokAWkSkhPVl3vkBOls0EYzw7bKFAFpEpobm5GYoqIFRw7oOCEVIl1WzdqkAWEcmbPXs+Jn6uCb1TxMtqaN7bzNDQkANVZUeBLCK+193dTU9PN8mSM5e7nS5ZVkMqmfTkOLICWUR8Lz1+fL4VFmmp4koA9u/fn9eaJkKBLCK+19zcDMaQHA/b87HhIkykmNbWVgcqy44CWUR8r7m5GVs0DYLhjI6PF0ZpaVEgi4jklLWWPR83Ey++8IReWqqokgMH2j230ZACWUR8rbOzk8GBflIZTOilJYunEY/HOXToUB4ry54CWUR8LZMbQk6XKhoba25ra8tLTROlQBYRX/vkk08gECRVNC3j96SKKsAYBbKISC61tbVhi6IQCGb+pkAIiqKeW2mhQBYRX2tpbSNREM36ffHCKC2tukIWEcmJgYEBerq7SBVnH8ipokqOHjnM4OBgHiqbGAWyiPhWe3s7AMksxo/TksVj7/HSHXsKZBHxrXQgZzOhl+bFlRYKZBHxrf3792OCYWykNOv32kgJJhRRIIuI5EJbWxvJwigYk/2bjSFROM1TKy0UyCLiW21t+0kWZT+hl5YsmkZLayvW2hxWNXEKZBHxpd7eXk6c6J1UIKeKK4kNDXH06NEcVjZxCmQR8aXJTOilpd/rlWELBbKI+FJ6udpkAjm9XC4d7m5TIIuIL7W3t2NCBdhw8cRPEopgCks9sxZZgSwivtTW1kZioissThEviNKiIQsRkYmx1tK2v31SE3ppqaJpdHR0eGKzegWyiPhOT0/P2Kb0kxg/TksWRUkmEp7YrF6BLCK+k4sJvbT0ObwwjqxAFhHf+WMg52LIIvon53STAllEfGf//v2YSBE2XDT5kwVCUFShQBYRmYiW1taxFRY5Ei+I0uqBTYYUyCLiK8lkkv3795Mc3z4zF1LF0/js0CFGRkZyds6JUCCLiK8cPHiQ+OgoyeIcBnLRNKy1dHR05OycE6FAFhFfSe9fnMrlFbJHVlookEXEV1pbW8EEcrLCIi1VUA6BoAJZRCQbLS0t2KIoBIK5O2kggC2scP3pIQpkEfGVfS25XWGRlih0f6WFAllEfKOvr4/urmOkcjihl5YqmkbXsWMMDg7m/NyZUiCLiG+kN5LP5QqLtGSx+3sjK5BFxDfyscIiLb3SoqWlJefnzpQCWUR8o7W1NXe3TJ/GRkox4UL27t2b83NnSoEsIr6xb98+4oXTJr0p/VkZQ7yoij0fN+f+3BlSIIuILyQSCfa3t+dluCItWVJNx4F2hoeH89bG+SiQRcQXDh06RCIePzn5lg+pkmpSqRT79u3LWxvno0AWEV9IT7blY8lbWrJkOgDNze4MWyiQRcQXTt4ynYebQtJspBhTUOLaxJ4CWUR8IS+3TJ/FaFEVH+35OK9tnIsCWUQ8L5lMsmvXbuLjQwr5lCqppvOzQ/T39+e9rdMpkEXE89ra2ojFhkiWXpL3ttLjyJ988kne2zqdAllEPG/Xrl0AJMtm5r2tZEk14M7EngJZRDxv586dmIJSbEFp/hsLFUBRuQJZROR01lo+3LGT0ZIZjrXp1h17CmQR8bTPPvuM3uM9JMvyP36cliyZTnfXMXp6ehxrExTIIuJxO3fuBCBZmv/x47SUS+PICmQR8bRdu3ZhwgU5fYbehSSLq8AETk4mOkWBLCKe9uGOHcSLZ+Rnh7dzCYZJll3Cu++951ybKJBFxMN6enr47NAhR8eP0+IVczjQ3s7hw4cda1OBLCKelR4ySDiw/vh0iegcAN5//33H2lQgi4hn7dy5ExMIkSqucrxtW1gBRRW8++67jrWpQBYRz9q8ZQuJkul531DoXEbLZ7Nt23ZisZgj7SmQRcSTWlpa6DhwgPi0ea7VkKiYTSIRZ/v27Y60p0AWEU96/fXXwQRIVM53rYZk2UxMMMx7Dq22UCCLiOckk0le/3+/JV4xGxsudK+QQJDR8kv5w7vvYq3Nf3N5b0FEJEvbtm2j93gPiaoFbpdComIOPd3dJx8hlU8KZBHxnNdffx0TKji59MxNyfEaNm/enPe2FMgi4ilDQ0O8/fbvGJlW69rqilPZcBEEgo48QSSU9xYmKZFIsGnTJg4cOEBXVxc9PT1UVVVx1VVXsXTpUkpLHdgfVUQc8/vf/57R0RESVfVul+I4zwZyb28vv/nNb3jhhRfp7u4CwIQi2HARZmSQX/ziFxhjuOaalfzVX62joaHB5YpFZLKstbzyyitQWO7I45q8xnOBnEgk+PnPf84/PfMMoyMjJMsvZWTBLSTLayAYHjsolSQ4cJRg3yE2bdvOB/fey0033cS6deuYNWuWux0QkQl7++23+fDDDxmec42zmwl5hKcCeefOnfyv7z7Kpx0HSETnMtKwnFTRtDMPDARJlteQLK9hdOYSIod38ebb7/DOO+/wjW98g7Vr1xIKeaprInIBfX19PPa9x7El1cQvaXK7HFd4IrX6+/t56qmnePnll6GwjKGGW0hG52b25lABo7NXEJ/RRGHHe6xfv56NG9/goYe+RWNjY34LF5GcefLJJ+nr62Oo6Q4wF+d6A1cD2VrLW2+9xePf/z4nTpxgdOYSRi694o9DE9mcK1JMbMHNhHraaf30fe6//37uvPNO1q1bR1lZWR6qF5Fc2bRpE6+99hojNctc2UjIK1wL5B07dvCDH6xnz56PsCXVDC3+AqmSyX8Qicpa+strKDi0nRd/9Ss2vvEm/+6+e1m9ejXhcPZBLyL5tXv3bv7HP/wDFEUZvXSZ2+W4ytFATiQSbNmyheef/yWbN2+CghKG560iPn1hbn9FCRUwMu9a4tMbSHW8z3e/+12e/tGPWPvlL3PHHXdQUlKSu7ZEZEKstTz33HOsX/9/SEVKGKy/GQKeGEV1jSO9Hxoa4plnnuHV117jRG8vJlzI8OyriV+yOK8fQKq4isHGzxPsO0Ty8C6eeuopfvj001y9YgWrVq1i5cqVVFdXYy7C2VwRtwwNDbFp0yZ+/etfs3XrVhLTaonV/hmEIjlvKzBwlFBfJ4nyGlKlM3J+/lxzJJC3bNnCc889R6JiNvEFy0lUzHbuDhxjSFbMZqhiNoHBLsJd+3h3686Tm06XlpVRV1dH7bx5VFZWUlFRQVlZGYFAYPztJqNNRdKh7sQGJCJuONuFSyY/76lUiu7ubo4cOcLBgwfZvv1DEok4JlLE8Nxric9YnJclboGBo1R1vMWff+5zvLxhA91zb/B8KF8wkI0x9wH3Acydm+HKh9OkUikARuZcffZlbA5JlVQzUlLNiL2W4MBRIp07GTjxKbt27mTX+KPGRSS/rAkwPP8GEpW1eV1NEerr5M8/9zn++j/+BwB+8l4bo34PZGvtemA9wIoVKyZ1+Rc++jHxGU2OPs77VCYeI9Szn1Dvp4QGDkMqCUB5RQW18+YRjUb/5MpYRCbPWou1loGBAQ50dNB17BhFbW+ROnYJwzVXkKzIz81cifIaXt6wAYCXN2wgMfeGvLSTS44MWSxdupSV117L5k2biBxtJlU6g+GZS8d2UXIg+MxwH5EjuynoasGmElw6axZ/dvuXWLlyJfX19USj7vwHIXKxsdbS3t7OO++8w4ZXX6Xzk9cYqVnK6Kyrcn61nCqdQffcG/jJe20kfDBcAQ4FcmVlJd/5x3+ku7ubjRs38sKLL9LZ8tuxYJ69gmSenihr4jEiB7cQ6W4hGAyy+vbbuOeee5g/370nEIhczIwx1NXVUVdXx9q1a3niiSd45ZVXCA0cJVZ/AzZcnNP2UqUzPD9McSpH15hUVVWxdu1a7r77bl599VV++PSPON78CvHKOkbmXju2zV0u2BThY3spOrQNYxPc8+Uvs3btWqqrq3NzfhGZtMLCQh566CGWLVvGo48+hml9k8HGz1+Ue1ikubLoLxQKsWbNGm699VZ+9rOf8eyPf0zko88YmnU1ieqGSX0ggaFuitrfJTB4jGVXXsl/+pu/Yd489x6SKCLnt3r1alKpFN/5zncIH2seW3VxkXL1hvGCggK+9rWv8fQPf8hlixZS1P57ivduIBA7nv3JUgkiB7dQsufXRENxvv3tb/O9xx5TGIv4wO23385Vy5dTdHALZmTA7XJc44kdPObNm8cT3/8+Dz74IOWpAUo++hWRTzdDcvTCb7YpQl0tlH30AgWdO7l99W3884+f5eabb9ZKCRGfMMbwrQcfJBIKUnjgXbhI1/N7IpABAoEAa9as4V/+5Z+5ffVtFBzeRfmO5yg48B4mduKM4018iFBXC6V7XqJo/++on3UJjz76KA8//DDl5eUu9EBEJqOmpob77ruX0ImDhHra3C7HFZ67cTwajfLwww9z11138fzzz/PGG28QOfoxpqCEZKiYVLiQ0OgADI0Na9RcOov7vvVfuf7660+uIRYRf7rrrrt4+eWXaT2ymwE9wsk7Fi1axCOPPMIDDzzAa6+9RkdHB11dXRw91sWM6QtYvnw5V1xxBQ0NDQSD7j8IUUQmLxgMsmbNGp544gkCQz2kiivdLslRng3ktMrKSr7yla+4XYaIOOSmm27ifz/5JOHuVkYuskDW7/gi4inRaJSV11xDwfE2sCm3y4HEKKSSFBYW5r0pBbKIeM7q1auxI4ME+zrdLoVQ3yEArrzyyry3pUAWEc+57rrrKCouJtzd4nYphHo/paS0jKam/D94VYEsIp5TUFDATTfeSKS3A5Jx9wqxKSL9h7h25TWOPMlegSwinnTbbbdhk3FCxw+4VkNgsAs7GmPVqlXOtOdIKyIiWVqyZAnTZ8wg3LPftRpCvZ9ijOHqq692pD0Fsoh4UiAQYOU11xAePOLaaotI30Euu/xyx+7+VSCLiGctXboUmxid2IZjk2RGBzGD3ay67jrH2lQgi4hnLVmyBIBg/xHH2w71fgqMrfhwigJZRDxr5syZVFZVuxLIwRMHmT5jBrW1tY61qUAWEc8yxnDlFcuIDB51dkvOVJJIfyf/atUqR7fxVSCLiKctWbIEOzqIGel3rM3AUA82GeeKK65wrE1QIIuIxy1duhSA4IBzwxbBoS4AGhsbHWsTFMgi4nG1tbWUlJQ6Oo4cHOyirKycmTNnOtYmKJBFxOMCgQBLliwhMuhcIIeGuli8eLHjj4FTIIuI5y1bthRiJzDxWP4bS8YxsV4WL16U/7ZOo0AWEc9zcj1ycKgbrHV8/BgUyCLiA42NjYTDYUcm9gKDYxN6ixbpCllE5AzhcJjFTU2EBo/mva3g4DGqqqdTWen846MUyCLiC40LFxKMHc/7RkPhWDdNLowfgwJZRHyivr4em0wQGO7LXyOJEYj1uTJcAQpkEfGJ+vp6AAKxnry1EXRx/BgUyCLiE/PmzSMQDBIYymcgHwNg4cKFeWvjfBTIIuILkUiEObPnEBzK397IgcEuai6dRVlZWd7aOG/7rrQqIjIBDQ0LCI/kL5AjsW4ua1qct/NfiAJZRHyjvr4eOzwwNvmWY2Z0CDsy6MoNIWkKZBHxjfTEXjAP48jpx0QtWLAg5+fOuAbXWhYRyVI+V1qkA7muri7n5864BtdaFhHJUmVlJWXlFXlZaRGMHaeiIko0Gs35uTOlQBYR3zDG0NCwgFAenkIdjPVSXz8/5+fNhgJZRHxlQX392PBCLm+htpbg8HFXhytAgSwiPlNfXw+pZE5voTYj/dhkQoEsIpKNkxN7ORxHDsR6AXcn9ECBLCI+k49bqIMeWGEBCmQR8ZlwOMzcOXMJ5nDpWyDWw/QZl1BcXJyzc06oDldbFxGZgIaGBYSHc7fSIjR8ggUur7AABbKI+FBdXR12ZDA3t1CnkphYr+vDFaBAFhEfSodnejJuMgIjfWBTCmQRkYmora0F/jgZNxmBIW9M6IECWUR86JJLLqGgsDA3V8ix4wQCAebMmZODyiZZi9sFiIhkKxAIUFtbSyAHE3uB2HFqLp1FQUFBDiqbZC1uFyAiMhH18+cTHp78FXJ4xBsrLECBLCI+VVtbix2NYeKxiZ8kmYDYCebPVyCLiExYLlZaBMavsNOThG5TIIuIL6VDNDCJlRbp26/T+2O4TYEsIr5UXV1NcUnJpK6Qg7HjRCIF1NTU5LCyiVMgi4gvGWOoq60jOImVFoFYD7V1tQSDwdwVNgkKZBHxrfnz6wgN94K12b/ZWsLDvSzwyHAFKJBFxMfq6uqw8ZEJrbQwiRh2NOaZFRagQBYRH/vjSovshy3St0x7ZUIPFMgi4mOTCuTx/ZS9sIdFmgJZRHwrGo1SVl4xoUAODh0nOq2SaDSah8omRoEsIr5Wn57Yy1Jo+DgNC7wzXAEKZBHxufnz5xOM9YJNZf4mm8LEej01fgwKZBHxuYULF2KTcQLDJzJ+T2D4BKSSnlphAQpkEfG5RYsWARAY7Mr4PekVFgpkEZEcmjNnDgWFhQSzCeRYD4FAgLlz5+axsuwpkEXE14LBII2NjYSGMg/k4NBxZs+ZQyQSyWNl2VMgi4jvLV60aGzntlQyo+PDI700LFiQ56qyp0AWEd9btGgRpJKZrUdOjGKH+z03fgwKZBGZAtITe5mMIwc9eIdemgJZRHxv5syZlJaVERg8dsFjg/2HAWhqasp3WVlTIIuI7xljaFq8mPBQ9wWPDfV3Ujd/vqdumU5TIIvIlNDY2IiJHYdk/NwHpRIEB46yYvly5wrLggJZRKaERYsWgbUEx5+TdzbBgWOQSnLllVc6WFnmFMgiMiVkcsdesO8zAoEAy5Ytc6qsrCiQRWRKqKqqorKyiuB5JvbC/Z00LFxISUmJg5VlToEsIlNGU9NiwrFzTOwl4wQGuzw7fgwKZBGZQi6//HKIncDEztz5Ldh/GGzKs+PHoEAWkSnk1ltvJRgMEjn68Rmvhfo7CYZCY6HtUQpkEZkyqqqquPHGGynoaTlj+Vuo/zCXNV1GYWGhS9VdmAJZRKaUu+++G5sYJdy1749/mRghMNjF8uVXuVdYBhTIIjKlNDU1sbCxkcJjzWAtWEvk8G4AT48fgwJZRKage770JYj1Euw7RMGnmyjo3MEtt9zq6fFjUCCLyBR0ww03UF4Rpaj1TSJHPuKLX/wif/u3/4VAwNuR5+3qREQmIBKJ8MW77sQk43z961/nm9/8pufDGCDkdgEiIvnw1a9+leuvv96TG9Gfi/f/yxARmYBQKOSrMAYFsoiIZyiQRUQ8QoEsIuIRCmQREY9QIIuIeIQCWUTEIxTIIiIeoUAWEfEIBbKIiEcokEVEPEKBLCLiEQpkERGPUCCLiHiEAllExCMUyCIiHqFAFhHxCAWyiIhHKJBFRDxCgSwi4hHGWpv5wcYcAw7kr5yMVANdLteQa1OxT6B++Y36lT/zrLXTL3RQVoHsBcaYLdbaFW7XkUtTsU+gfvmN+uU+DVmIiHiEAllExCP8GMjr3S4gD6Zin0D98hv1y2W+G0MWEZmq/HiFLCIyJXkykI0xtxtj9hpjWowxD5/l9QJjzHPjr39gjKl1vsrsZdCv/2yM2WOM2WmM2WiMmedGndm6UL9OOe4eY4w1xvhixjuTfhlj1o5/Zh8ZY37idI0TkcHP4VxjzJvGmO3jP4ufd6PObBhjnjbGHDXG7D7H68YY88R4n3caY65yusaMWGs99QcIAq3AfCAC7ACaTjvm3wNPjX/9F8Bzbtedo37dCBSPf/3AVOnX+HFlwO+A94EVbtedo8+rAdgOTBv/fobbdeeoX+uBB8a/bgLa3a47g379G+AqYPc5Xv88sAEwwLXAB27XfLY/XrxCvgZosda2WWtHgZ8Bd552zJ3AM+Nf/wK42RhjHKxxIi7YL2vtm9baofFv3wdmO1zjRGTyeQH8HfA/gWEni5uETPp1L/CktfY4gLX2qMM1TkQm/bJA+fjXFcBnDtY3Idba3wE95znkTuBZO+Z9IGqMqXGmusx5MZBnAZ+e8v3B8b876zHW2gRwAqhypLqJy6Rfp1rH2P/oXnfBfhljrgTmWGt/42Rhk5TJ57UQWGiM+YMx5n1jzO2OVTdxmfTrvwF/aYw5CLwC/LUzpeVVtv/+XBFyu4CzONuV7ulLQTI5xmsyrtkY85fACuD6vFaUG+ftlzEmAHwP+LpTBeVIJp9XiLFhixsY+23mHWPM5dba3jzXNhmZ9OsrwD9Zax81xlwH/Hi8X6n8l5c3vsgML14hHwTmnPL9bM78lenkMcaYEGO/Vp3v1xUvyKRfGGNuAR4BvmCtHXGotsm4UL/KgMuBt4wx7YyN373kg4m9TH8Of2WtjVtr9wN7GQtoL8ukX+uAnwNYa98DChnbD8LPMvr35zYvBvJmoMEYU2eMiTA2affSace8BHxt/Ot7gDfs+Mi9h12wX+O/2v+AsTD2w3gkXKBf1toT1tpqa22ttbaWsbHxL1hrt7hTbsYy+Tl8kbGJWIwx1YwNYbQ5WmX2MulXB3AzgDFmMWOBfMzRKnPvJeDfjq+2uBY4Ya3tdLuoM7g9q3ieGdFPGJsNfmT87/47Y/+QYewH5P8CLcAmYL7bNeeoX78FjgAfjv95ye2ac9Gv0459Cx+sssjw8zLAY8AeYBfwF27XnKN+NQF/YGwFxofAbW7XnEGffgp0AnHGrobXAfcD95/yWT053uddXv0Z1J16IiIe4cUhCxGRi5ICWUTEIxTIIiIeoUAWEfEIBbKIiEcokEVEPEKBLCLiEQpkERGP+P9RG7GkCSJ55wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104a4f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "print(skew(y_train_0))\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.violinplot(y_train_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1 - sum(y_train_0) / len(y_train_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple check shows that 90.1% of the images are not zero. Any time you guess the image is not zero, you will be right 90.13% of the time. \n",
    "\n",
    "Bare this in mind when you are dealing with **skewed datasets**. Because of this, accuracy is generally not the preferred performance measure for classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(clf, X_train, y_train_0, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_train_0, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row: actual class\n",
    "\n",
    "Each column: predicted class\n",
    "\n",
    "First row: Non-zero images, the negative class:\n",
    "* 53360 were correctly classified as non-zeros. **True negatives**. \n",
    "* Remaining 717 were wrongly classified as 0s. **False positive**\n",
    "\n",
    "\n",
    "Second row: The images of zeros, the positive class:\n",
    "* 395 were incorrectly classified as 0s. **False negatives**\n",
    "* 5528 were correctly classified as 0s. **True positives**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\confusion matrix.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision\n",
    "\n",
    "**Precision** measures the accuracy of positive predictions. Also called the `precision` of the classifier\n",
    "\n",
    "$$\\textrm{precision} = \\frac{\\textrm{True Positives}}{\\textrm{True Positives} + \\textrm{False Positives}}$$\n",
    "\n",
    "<img src=\"img\\precision.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_score(y_train_0, y_train_pred) # 5528 / (717 + 5528)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5528 / (717+5528)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall\n",
    "\n",
    "`Precision` is typically used with `recall` (`Sensitivity` or `True Positive Rate`). The ratio of positive instances that are correctly detected by the classifier.\n",
    "\n",
    "$$\\textrm{recall} = \\frac{\\textrm{True Positives}}{\\textrm{True Positives} + \\textrm{False Negatives}}$$\n",
    "\n",
    "<img src=\"img\\recall.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_score(y_train_0, y_train_pred) # 5528 / (395 + 5528)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5528 / (395 + 5528)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "\n",
    "$F_1$ score is the harmonic mean of precision and recall. Regular mean gives equal weight to all values. Harmonic mean gives more weight to low values.\n",
    "\n",
    "\n",
    "$$F_1=\\frac{2}{\\frac{1}{\\textrm{precision}}+\\frac{1}{\\textrm{recall}}}=2\\times \\frac{\\textrm{precision}\\times \\textrm{recall}}{\\textrm{precision}+ \\textrm{recall}}=\\frac{TP}{TP+\\frac{FN+FP}{2}}$$\n",
    "\n",
    "The $F_1$ score favours classifiers that have similar precision and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_score(y_train_0, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision / Recall Tradeoff\n",
    "\n",
    "Increasing precision reduced recall and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\precision-recall.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier is designed to pick up zeros.\n",
    "\n",
    "12 observations\n",
    "\n",
    "***\n",
    "\n",
    "**Central Arrow**\n",
    "\n",
    "Suppose the decision threshold is positioned at the central arrow: \n",
    "* We get 4 true positives (We have 4 zeros to the right of the central arrow)\n",
    "* 1 false positive which is actually seven.\n",
    "\n",
    "At this threshold, the **precision accuracy** is $\\frac{4}{5}=80\\%$\n",
    "\n",
    "However, out of the 6 zeros, the classifier only picked up 4. The **recall accuracy** is $\\frac{4}{6}=67\\%$\n",
    "\n",
    "***\n",
    "\n",
    "**Right Arrow**\n",
    "\n",
    "* We get 3 true positives\n",
    "* 0 false positive\n",
    "\n",
    "At this threshold, the **precision accuracy** is $\\frac{3}{3}=100\\%$\n",
    "However, out of the 6 zeros, the classifier only picked up 3. The **recall accuracy** is $\\frac{3}{6}=50\\%$\n",
    "\n",
    "***\n",
    "\n",
    "**Left Arrow**\n",
    "\n",
    "* We get 6 true positives\n",
    "* 2 false positive\n",
    "\n",
    "At this threshold, the **precision accuracy** is $\\frac{6}{8}=75\\%$\n",
    "Out of the 6 zeros, the classifier picked up all 6. The **recall accuracy** is $\\frac{6}{6}=100\\%$\n",
    "\n",
    "***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_scores = clf.decision_function(X[1000].reshape(1, -1))\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_some_digits_pred = (y_scores > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_some_digits_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 40000\n",
    "y_some_digits_pred = (y_scores > threshold)\n",
    "y_some_digits_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(clf, X_train, y_train_0, cv=3, method='decision_function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)); plt.hist(y_scores, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the decision scores, we can compute precision and recall for all possible thresholds using the `precision_recall_curve()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(y_train_0, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g--\", label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylim([-0.5,1.5])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)); \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this chart, you can select the threshold value that gives you the best precision/recall tradeoff for your task.\n",
    "\n",
    "Some tasks may call for higher precision (accuracy of positive predictions). Like designing a classifier that picks up adult contents to protect kids. This will require the classifier to set a high bar to allow any contents to be consumed by children.\n",
    "\n",
    "Some tasks may call for higher recall (ratio of positive instances that are correctly detected by the classifier). Such as detecting shoplifters/intruders on surveillance images - Anything that remotely resemble \"positive\" instances to be picked up.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also plot precisions against recalls to assist with the threshold selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)); \n",
    "plt.plot(precisions, recalls);\n",
    "plt.xlabel('recalls');\n",
    "plt.ylabel('precisions');\n",
    "plt.title('PR Curve: precisions/recalls tradeoff');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting High Precisions\n",
    "\n",
    "Let's aim for 90% precisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)); \n",
    "plt.plot(thresholds, precisions[1:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = len(precisions[precisions < 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_90 = (y_scores > 21454)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_score(y_train_0, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_score(y_train_0, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting High Precisions\n",
    "\n",
    "Let's aim for 99% precisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = len(precisions[precisions < 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_90 = (y_scores > thresholds[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_score(y_train_0, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_score(y_train_0, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Receiver Operating Characteristics (ROC) Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of plotting precision versus recall, the ROC curve plots the `true positive rate` (another name for recall) against the `false positive rate`. The `false positive rate` (FPR) is the ratio of negative instances that are incorrectly classified as positive. It is equal to one minus the `true negative rate`, which is the ratio of negative instances that are correctly classified as negative.\n",
    "\n",
    "The TNR is also called `specificity`. Hence the ROC curve plots `sensitivity` (recall) versus `1 - specificity`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\tnr_and_fpr.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train_0, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)); \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_0, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PR curve whenever the **positive class is rare** or when you care more about the false positives than the false negatives\n",
    "\n",
    "Use ROC curve whenever the **negative class is rare** or when you care more about the false negatives than the false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the example above, the ROC curve seemed to suggest that the classifier is good. However, when you look at the PR curve, you can see that there are room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_clf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_probas_forest = cross_val_predict(f_clf, X_train, y_train_0,\n",
    "                                   cv=3, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:, 1]\n",
    "fpr_forest, tpr_forest, threshold_forest = roc_curve(y_train_0, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)); \n",
    "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_0, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_clf.fit(X_train, y_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_rf = cross_val_predict(f_clf, X_train, y_train_0, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_score(y_train_0, y_train_rf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_score(y_train_0, y_train_rf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_train_0, y_train_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
